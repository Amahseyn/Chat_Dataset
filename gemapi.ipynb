{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee391e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mio/anaconda3/envs/llmagent/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\")) # Make sure your API key is set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9822ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_63185/2682852144.py:5: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('data.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV\n",
    "try:\n",
    "    df = pd.read_csv('data.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'your_real_estate_dataset.csv' not found. Make sure the file path is correct.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# Select the first 100 rows\n",
    "df_subset = df.head(100)\n",
    "\n",
    "# Convert each row into a descriptive text string\n",
    "documents = []\n",
    "for index, row in df_subset.iterrows():\n",
    "    # Start building the description\n",
    "    desc_parts = []\n",
    "\n",
    "    # Basic Information\n",
    "    if pd.notna(row.get('building_type')) and pd.notna(row.get('area')):\n",
    "        desc_parts.append(f\"This is a {row.get('building_type')} with an area of {row.get('area')} square feet.\")\n",
    "    elif pd.notna(row.get('building_type')):\n",
    "        desc_parts.append(f\"This is a {row.get('building_type')}.\")\n",
    "    elif pd.notna(row.get('area')):\n",
    "        desc_parts.append(f\"This property has an area of {row.get('area')} square feet.\")\n",
    "\n",
    "    if pd.notna(row.get('property_description')):\n",
    "        desc_parts.append(f\"Description: {row.get('property_description')}\")\n",
    "    elif pd.notna(row.get('property_overview')): # Fallback to overview if description is missing\n",
    "        desc_parts.append(f\"Overview: {row.get('property_overview')}\")\n",
    "\n",
    "    # Location\n",
    "    location_parts = []\n",
    "    if pd.notna(row.get('address')) and str(row.get('address')).strip(): # Check if address is not NaN and not just whitespace\n",
    "        location_parts.append(f\"Address: {row.get('address')}\")\n",
    "    if pd.notna(row.get('locality')):\n",
    "        location_parts.append(f\"located in {row.get('locality')}\")\n",
    "    if pd.notna(row.get('city')):\n",
    "        location_parts.append(f\"{row.get('city')}\")\n",
    "    if pd.notna(row.get('division')):\n",
    "        location_parts.append(f\"{row.get('division')}\")\n",
    "    if location_parts:\n",
    "        desc_parts.append(\", \".join(filter(None, location_parts)) + \".\")\n",
    "\n",
    "\n",
    "    # Rooms and Price\n",
    "    if pd.notna(row.get('num_bed_rooms')):\n",
    "        desc_parts.append(f\"It has {int(row.get('num_bed_rooms', 0))} bedroom(s).\") # Convert to int for cleaner text\n",
    "    if pd.notna(row.get('num_bath_rooms')):\n",
    "        desc_parts.append(f\"and {int(row.get('num_bath_rooms', 0))} bathroom(s).\") # Convert to int\n",
    "\n",
    "    if pd.notna(row.get('price')) and pd.notna(row.get('purpose')):\n",
    "        desc_parts.append(f\"The property is for {row.get('purpose')} at a price of {row.get('price')}.\") # Assuming price is in local currency\n",
    "    elif pd.notna(row.get('price')):\n",
    "        desc_parts.append(f\"The price is {row.get('price')}.\")\n",
    "    elif pd.notna(row.get('purpose')):\n",
    "        desc_parts.append(f\"The purpose is {row.get('purpose')}.\")\n",
    "\n",
    "\n",
    "    # Amenities (count only if > 0)\n",
    "    amenities = []\n",
    "    if pd.notna(row.get('relaxation_amenity_count')) and row.get('relaxation_amenity_count') > 0:\n",
    "        amenities.append(f\"{int(row.get('relaxation_amenity_count'))} relaxation amenities\")\n",
    "    if pd.notna(row.get('security_amenity_count')) and row.get('security_amenity_count') > 0:\n",
    "        amenities.append(f\"{int(row.get('security_amenity_count'))} security amenities\")\n",
    "    if pd.notna(row.get('maintenance_or_cleaning_amenity_count')) and row.get('maintenance_or_cleaning_amenity_count') > 0:\n",
    "        amenities.append(f\"{int(row.get('maintenance_or_cleaning_amenity_count'))} maintenance/cleaning amenities\")\n",
    "    if pd.notna(row.get('social_amenity_count')) and row.get('social_amenity_count') > 0:\n",
    "        amenities.append(f\"{int(row.get('social_amenity_count'))} social amenities\")\n",
    "    # Add other amenity counts as needed\n",
    "\n",
    "    if amenities:\n",
    "        desc_parts.append(f\"It includes: {', '.join(amenities)}.\")\n",
    "\n",
    "    # You might not need to include URLs or IDs in the text for chat,\n",
    "    # unless you specifically want to retrieve them. The property_url could be useful metadata though.\n",
    "    # For this example, we'll keep it focused on descriptive text.\n",
    "    # You could also add:\n",
    "    # if pd.notna(row.get('id')):\n",
    "    #     desc_parts.append(f\"Property ID: {row.get('id')}\")\n",
    "\n",
    "    # Join all parts into a single string\n",
    "    doc_text = \" \".join(desc_parts)\n",
    "    documents.append(doc_text)\n",
    "\n",
    "# 'documents' now contains a list of detailed strings.\n",
    "# print(f\"Created {len(documents)} text documents from the CSV.\")\n",
    "# if documents:\n",
    "#     print(\"\\nExample document from your first row:\")\n",
    "#     print(documents[0])\n",
    "# else:\n",
    "#     print(\"No documents created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2032929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=os.getenv(\"GOOGLE_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e0ac407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created successfully.\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS # Or Chroma, etc.\n",
    "\n",
    "if not documents:\n",
    "    print(\"No documents were created from the CSV. Cannot proceed with embedding.\")\n",
    "    exit()\n",
    "\n",
    "vector_store = FAISS.from_texts(texts=documents, embedding=embeddings_model)\n",
    "print(\"Vector store created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795834ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_relevant_property_info(query, vector_store, k=3): # Retrieve top 3 relevant rows\n",
    "    relevant_docs = vector_store.similarity_search(query, k=k)\n",
    "    return [doc.page_content for doc in relevant_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6123aedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel('gemini-1.5-flash') # Or gemini-1.5-flash, gemini-1.5-pro for more advanced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55ca9810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Estate AI Agent. Type 'quit' to exit.\n",
      "AI: Please provide the user's current question. I need the question to be able to answer it based on the provided data.\n",
      "\n",
      "AI: Hi!  How can I help you with your real estate search today?\n",
      "\n",
      "AI: Hi! How can I help you find your dream home in Dhaka?\n",
      "\n",
      "AI: Please ask your question.\n",
      "\n",
      "Exiting chat.\n"
     ]
    }
   ],
   "source": [
    "def generate_real_estate_response(user_query, vector_store_instance, llm_model, chat_history_list=None):\n",
    "    retrieved_context_list = retrieve_relevant_property_info(user_query, vector_store)\n",
    "    if not retrieved_context_list:\n",
    "        context_str = \"No specific property information found in the first 100 rows for this query.\"\n",
    "    else:\n",
    "        context_str = \"\\n\\n\".join(retrieved_context_list)\n",
    "\n",
    "    # Prompt can be slightly adjusted to be more explicit about new vs. ongoing context\n",
    "    prompt = f\"\"\"You are a helpful AI assistant specializing in real estate from a provided dataset.\n",
    "Answer the user's CURRENT question based on the following NEWLY RETRIEVED property information and our ongoing conversation.\n",
    "If the information to answer the current question is not in the NEWLY RETRIEVED property information,\n",
    "and you cannot infer it from the conversation history, clearly state that the information is not available in the loaded data for this specific query.\n",
    "Do not make up information.\n",
    "\n",
    "NEWLY RETRIEVED Property Information:\n",
    "{context_str}\n",
    "\n",
    "User's CURRENT Question: {user_query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "    if chat_history_list:\n",
    "        chat_session = llm_model.start_chat(history=chat_history_list) # Use llm_model parameter\n",
    "        try:\n",
    "            response = chat_session.send_message(prompt)\n",
    "            updated_history = chat_session.history\n",
    "        except Exception as e: # ADDED ERROR HANDLING\n",
    "            print(f\"Error sending message to Gemini: {e}\")\n",
    "            error_message = f\"Sorry, I encountered an error: {e}\"\n",
    "            if hasattr(e, 'response') and hasattr(e.response, 'prompt_feedback'):\n",
    "                error_message += f\" Prompt Feedback: {e.response.prompt_feedback}\"\n",
    "            return error_message, chat_history_list # Return history and error\n",
    "\n",
    "    else: # First turn\n",
    "        try:\n",
    "            response = llm_model.generate_content(prompt) # Use llm_model parameter\n",
    "            updated_history = [\n",
    "                {'role': 'user', 'parts': [{'text': user_query}]},\n",
    "                {'role': 'model', 'parts': [{'text': response.text}]}\n",
    "            ]\n",
    "        except Exception as e: # ADDED ERROR HANDLING\n",
    "            print(f\"Error generating content with Gemini: {e}\")\n",
    "            error_message = f\"Sorry, I encountered an error: {e}\"\n",
    "            if hasattr(e, 'response') and hasattr(e.response, 'prompt_feedback'):\n",
    "                error_message += f\" Prompt Feedback: {e.response.prompt_feedback}\"\n",
    "            return error_message, []\n",
    "\n",
    "    return response.text, updated_history\n",
    "\n",
    "if 'vector_store' in globals() and vector_store and 'model' in globals(): # Ensure model is also available\n",
    "    print(\"Real Estate AI Agent. Type 'quit' to exit.\")\n",
    "    current_conversation_history = [] # Initialize empty history list\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Exiting chat.\")\n",
    "            break\n",
    "\n",
    "        # Call the modified function, passing the actual vector_store and model objects,\n",
    "        # and the current_conversation_history\n",
    "        ai_response_text, updated_conversation_history = generate_real_estate_response(\n",
    "            user_input,\n",
    "            vector_store,  # Pass your global vector_store instance\n",
    "            model,         # Pass your global model instance\n",
    "            current_conversation_history\n",
    "        )\n",
    "\n",
    "        print(f\"AI: {ai_response_text}\")\n",
    "        current_conversation_history = updated_conversation_history # IMPORTANT: Update history for the next turn\n",
    "\n",
    "        # Optional: For debugging the history content\n",
    "        # print(\"\\n--- Current Conversation History ---\")\n",
    "        # for turn in current_conversation_history:\n",
    "        #     print(f\"{turn['role']}: {turn['parts'][0]['text']}\")\n",
    "        # print(\"--------------------------------\\n\")\n",
    "else:\n",
    "    print(\"Vector store or language model not initialized. Please check previous steps.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
